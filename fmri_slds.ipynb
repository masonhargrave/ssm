{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching Linear Dynamical Systems fMRI Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "npr.seed(0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "color_names = [\"windows blue\",\n",
    "               \"red\",\n",
    "               \"amber\",\n",
    "               \"faded green\",\n",
    "               \"dusty purple\",\n",
    "               \"orange\",\n",
    "               \"clay\",\n",
    "               \"pink\",\n",
    "               \"greyish\",\n",
    "               \"mint\",\n",
    "               \"cyan\",\n",
    "               \"steel blue\",\n",
    "               \"forest green\",\n",
    "               \"pastel purple\",\n",
    "               \"salmon\",\n",
    "               \"dark brown\"]\n",
    "\n",
    "colors = sns.xkcd_palette(color_names)\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "import ssm\n",
    "from ssm.util import random_rotation, find_permutation\n",
    "from ssm.plots import plot_dynamics_2d\n",
    "\n",
    "save_figures = False\n",
    "\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fMRI data\n",
    "mat = scipy.io.loadmat('data/logan_tmsPredict_aug2019.mat')\n",
    "data = mat['logan_timeSeries_roi25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters of the SLDS\n",
    "time_bins = data.shape[0]    # number of time bins\n",
    "n_disc_states = 5       # number of discrete states\n",
    "latent_dim =  18       # number of latent dimensions\n",
    "emissions_dim = data.shape[1]      # number of observed dimensions\n",
    "n_scans = data.shape[2]\n",
    "\n",
    "cmap_limited = ListedColormap(colors[0:n_disc_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find peaks and troughs of the data\n",
    "\n",
    "maximum = [np.max(data[:,:,i]) for i in range(n_scans)]\n",
    "minimum = [np.min(data[:,:,i]) for i in range(n_scans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot max and min peaks and troughs \n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(10,5))\n",
    "axs[0].hist(maximum)\n",
    "axs[0].set_title('Maximum')\n",
    "axs[1].hist(minimum)\n",
    "axs[1].set_title('Minimum')\n",
    "plt.suptitle('fMRI Amplitude Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit using Laplace-EM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SLDS Models to Each Time Series\n",
    "\n",
    "states=[]\n",
    "As = []\n",
    "bs = []\n",
    "covs = []\n",
    "elbos = []\n",
    "\n",
    "\n",
    "for i in range(n_scans):\n",
    "    print(\"Fitting SLDS with Laplace-EM\")\n",
    "\n",
    "    # Create the model and initialize its parameters\n",
    "    slds = ssm.SLDS(emissions_dim, n_disc_states, latent_dim, emissions=\"gaussian_orthog\")\n",
    "\n",
    "    # Fit the model using Laplace-EM with a structured variational posterior\n",
    "    q_lem_elbos, q_lem = slds.fit(data[:,:,i], method=\"laplace_em\",\n",
    "                                   variational_posterior=\"structured_meanfield\",\n",
    "                                   num_iters=3, alpha=0.0)\n",
    "\n",
    "    # Get the posterior mean of the continuous states\n",
    "    q_lem_x = q_lem.mean_continuous_states[0]\n",
    "\n",
    "    # Find most likely states\n",
    "    q_lem_z = slds.most_likely_states(q_lem_x, data[:,:,i])\n",
    "\n",
    "    # Smooth the data under the variational posterior\n",
    "    q_lem_y = slds.smooth(q_lem_x, data[:,:,i])\n",
    "    \n",
    "\n",
    "    \n",
    "    As.append(slds.dynamics.As)\n",
    "    bs.append(slds.dynamics.bs)\n",
    "    covs.append(slds.dynamics.Sigmas)\n",
    "    states.append(q_lem_z)\n",
    "    elbos.append(q_lem_elbos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ELBOs\n",
    "\n",
    "for i in range(n_scans):\n",
    "    q_lem_elbos = elbos[i]\n",
    "    plt.plot(q_lem_elbos, label=\"Laplace-EM: Structured Mean-Field Posterior\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"ELBO\")\n",
    "    plt.legend(bbox_to_anchor=(1.0,1.0))\n",
    "    plt.title(\"Convergence for learning an SLDS\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Eigenvalues and Eigenvevtors of the matrices\n",
    "\n",
    "eig = [np.linalg.eig(As[i]) for i in range(n_scans)]\n",
    "e_vals = [eig[i][0] for i in range(n_scans)]\n",
    "e_vects = [eig[i][1] for i in range(n_scans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Eigenvalues\n",
    "\n",
    "r_cutoff = 0.5\n",
    "\n",
    "x = np.real(np.asarray(e_vals).flatten())\n",
    "y = np.imag(np.asarray(e_vals).flatten())\n",
    "\n",
    "unit_circle = plt.Circle((0,0), radius=1, color=colors[1], fill=False)\n",
    "inner_circle = plt.Circle((0,0), radius=r_cutoff, color=colors[2], fill=False)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(46,16))\n",
    "ax.scatter(x, y, s=1, color=colors[0])\n",
    "\n",
    "ax.axhline(y=0, color = 'k', linewidth=0.5)\n",
    "ax.axvline(x=0, color = 'k', linewidth=0.5)\n",
    "\n",
    "ax.add_patch(unit_circle)\n",
    "ax.add_patch(inner_circle)\n",
    "\n",
    "ax.set_xlabel('Real')\n",
    "ax.set_ylabel('Imaginary')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.plot()\n",
    "\n",
    "plt.suptitle('Eigenvalues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the intrisic dimensionality of the dynamics\n",
    "\n",
    "e_vals_magnitudes = np.abs(np.asarray(e_vals).flatten()) # find magnitude of e.vals\n",
    "n_sig_evals = np.sum(e_vals_magnitudes > r_cutoff) # find number of e.vals with mag > r_cutoff\n",
    "intrisic_dim = n_sig_evals / (n_scans * n_disc_states) # find intrinsic dimensionality of dynamics\n",
    "print('intrisic dimensionality =',intrisic_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Inferred Latent States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inferred states for Each Time Series \n",
    "\n",
    "for i in range(n_scans):\n",
    "    plt.figure(figsize=(12,2))\n",
    "    plt.imshow(states[i][None,:], aspect='auto', cmap=cmap_limited)\n",
    "    plt.title('fMRI Inferred States')\n",
    "    plt.xlabel('Frames')\n",
    "    ax = plt.gca()\n",
    "    ax.set_yticks([])\n",
    "    #plt.savefig('scan_%i' % (i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on unseen data\n",
    "After learning a model from data, a common use-case is to compute the distribution over latent states given some new observations. For example, in the case of a simple LDS, we could use the Kalman Smoother to estimate the latent state trajectory given a set of observations. \n",
    "\n",
    "In the case of an SLDS (or Recurrent SLDS), the posterior over latent states can't be computed exactly. Instead, we need to live with a variational approximation to the true posterior. SSM allows us to compute this approximation using the `SLDS.approximate_posterior()` method. \n",
    "\n",
    "In the below example, we generate some new data from the true model. We then use the `approximate_posterior()` function to estimate the continuous and discrete states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data that was not used for fitting\n",
    "# Or cheat and do it anyway for practice ;)\n",
    "validation = data[:,:,-1]\n",
    "\n",
    "# Compute the approximate posterior over latent and continuous\n",
    "# states for the new data under the current model parameters.\n",
    "elbos, posterior = slds.approximate_posterior(validation,\n",
    "                                              method=\"laplace_em\",\n",
    "                                              variational_posterior=\"structured_meanfield\",\n",
    "                                              num_iters=3)\n",
    "\n",
    "# Verify that the ELBO increases during fitting. We don't expect a substantial increase:\n",
    "# we are updating the estimate of the latent states but we are not changing model params.\n",
    "plt.plot(elbos)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimating Latent States**  \n",
    "  \n",
    "`posterior` is now an `ssm.variational.SLDSStructuredMeanFieldVariationalPosterior` object. Using this object, we can estimate the continuous and discrete states just like we did after calling the fit function.\n",
    "\n",
    "In the below cell, we get the estimated continuous states as follows:\n",
    "```python\n",
    "posterior_x = posterior.mean_continuous_states[0]\n",
    "```\n",
    "This line uses the `mean_continuous_states` property of the posterior object, which returns a list, where each entry of the list corresponds to a single trial of data. Since we have only passed in a single trial the list will have length 1, and we take the first entry.\n",
    "\n",
    "We then permute the discrete and continuous states to best match the ground truth. This is for aesthetic purposes when plotting. The following lines compute the best permutation which match the predicted states (`most_likely`) to the ground truth discrete states (`data_z`). We then permute the states of the SLDS accordingly:\n",
    "```python\n",
    "\n",
    "most_likely = slds.most_likely_states(posterior_x, data)\n",
    "perm = find_permutation(data_z, most_likely)\n",
    "slds.permute(perm)\n",
    "z_est = slds.most_likely_states(posterior_x, data)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_est = posterior.mean_continuous_states[0]\n",
    "z_est = slds.most_likely_states(x_est, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_str = [\"$x_1$\", \"$x_2$\"]\n",
    "fig, axs = plt.subplots(2,1, figsize=(14,4))\n",
    "for (d, ax) in enumerate(axs):\n",
    "    ax.plot(x_est[:,d] + 4 * d, '-', color=colors[2], label=\"Laplace-EM\" if d==0 else None)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title_str[d], loc=\"left\", y=0.5, x=-0.03)\n",
    "axs[0].set_xticks([])\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "plt.suptitle(\"Estimated Continuous States\", va=\"bottom\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_z, model_x, model_y = slds.sample(time_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_str = [\"$x_1$\", \"$x_2$\"]\n",
    "fig, axs = plt.subplots(2,1, figsize=(14,4))\n",
    "for (d, ax) in enumerate(axs):\n",
    "    ax.plot(model_x[:,d] + 4 * d, '-', color=colors[0], label=\"'Naively Generated'\" if d==0 else None)\n",
    "    ax.plot(x_est[:,d] + 4 * d, '-', color=colors[2], label=\"Estimated\" if d==0 else None)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title_str[d], loc=\"left\", y=0.5, x=-0.03)\n",
    "axs[0].set_xticks([])\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "plt.suptitle(\" 'Naively Generated' and Estimated Continuous States\", va=\"bottom\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate by:\n",
    "    \n",
    "$x_{n+1, k} = A_kx_n + b + w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict n_gen continuous states by switching models simultaenously with estimated states\n",
    "\n",
    "A = slds.dynamics.As\n",
    "b = slds.dynamics.bs\n",
    "cov = slds.dynamics.Sigmas\n",
    "n_gen = 100\n",
    "\n",
    "mse = np.zeros(n_gen)\n",
    "mae = np.zeros(n_gen)\n",
    "\n",
    "for j in range(n_gen):\n",
    "    x = [x_est[0]]\n",
    "    \n",
    "    for i in range(time_bins-1):\n",
    "        k = z_est[i]\n",
    "        w = np.random.multivariate_normal(np.zeros(latent_dim), cov[k])\n",
    "        x_i = A[k]@x[-1] + b[k] + w\n",
    "        x.append(x_i)\n",
    "    \n",
    "    x_gen = np.vstack(x)\n",
    "    mse[j] = np.mean((x_est - x_gen)**2)\n",
    "    mae[j] = np.mean(np.abs(x_est - x_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and plot errors from each of the runs as compared to the estimated continuous states \n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8,4))\n",
    "axs[0].hist(mse)\n",
    "axs[0].set_title('Mean Squared Error')\n",
    "axs[1].hist(mae)\n",
    "axs[1].set_title('Mean Absolute Error')\n",
    "\n",
    "plt.suptitle(\"Error Distributions\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_str = [\"$x_{%i}$\" %i for i in range(latent_dim)]\n",
    "fig, axs = plt.subplots(latent_dim,1, figsize=(14,2*latent_dim))\n",
    "for (d, ax) in enumerate(axs):\n",
    "    ax.plot(x_gen[:,d] + 4 * d, '-', color=colors[0], label=\"Generated\" if d==0 else None)\n",
    "    ax.plot(x_est[:,d] + 4 * d, '-', color=colors[2], label=\"Estimated\" if d==0 else None)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title_str[d], loc=\"left\", y=0.5, x=-0.03)\n",
    "axs[0].set_xticks([])\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "plt.suptitle(\"Generated and Estimated Continuous States\", va=\"bottom\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Training, Validation and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fraction = .6\n",
    "validation_fraction = .2\n",
    "training_index = int(training_fraction * n_scans)\n",
    "validation_index = int(training_index + validation_fraction * n_scans)\n",
    "\n",
    "training_data = np.swapaxes(np.hstack(data[:,:,:training_index]),0,1)\n",
    "validation_data = np.swapaxes(np.hstack(data[:,:,training_index:validation_index]),0,1)\n",
    "test_data = np.swapaxes(np.hstack(data[:,:,validation_index:]),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SLDS Models to The Training Time Series\n",
    "\n",
    "print(\"Fitting SLDS with Laplace-EM\")\n",
    "\n",
    "# Create the model and initialize its parameters\n",
    "slds = ssm.SLDS(emissions_dim, n_disc_states, latent_dim, emissions=\"gaussian_orthog\")\n",
    "\n",
    "# Fit the model using Laplace-EM with a structured variational posterior\n",
    "q_lem_elbos, q_lem = slds.fit(training_data, method=\"laplace_em\",\n",
    "                               variational_posterior=\"structured_meanfield\",\n",
    "                               num_iters=3, alpha=0.0)\n",
    "\n",
    "# Get the posterior mean of the continuous states\n",
    "q_lem_x = q_lem.mean_continuous_states[0]\n",
    "\n",
    "# Find most likely states\n",
    "q_lem_z = slds.most_likely_states(q_lem_x, training_data)\n",
    "\n",
    "# Smooth the data under the variational posterior\n",
    "q_lem_y = slds.smooth(q_lem_x, training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ELBOs\n",
    "plt.plot(q_lem_elbos, label=\"Laplace-EM: Structured Mean-Field Posterior\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.legend(bbox_to_anchor=(1.0,1.0))\n",
    "plt.title(\"Convergence for learning an SLDS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,2))\n",
    "plt.imshow(q_lem_z[None,:], aspect='auto', cmap=cmap_limited)\n",
    "plt.title('fMRI Inferred States')\n",
    "plt.xlabel('Frames')\n",
    "ax = plt.gca()\n",
    "ax.set_yticks([])\n",
    "plt.savefig('scan_%i' % (i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the approximate posterior over latent and continuous\n",
    "# states for the new data under the current model parameters.\n",
    "elbos, posterior = slds.approximate_posterior(validation_data,\n",
    "                                              method=\"laplace_em\",\n",
    "                                              variational_posterior=\"structured_meanfield\",\n",
    "                                              num_iters=3)\n",
    "\n",
    "# Verify that the ELBO increases during fitting. We don't expect a substantial increase:\n",
    "# we are updating the estimate of the latent states but we are not changing model params.\n",
    "plt.plot(elbos)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_est = posterior.mean_continuous_states[0]\n",
    "z_est = slds.most_likely_states(x_est, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(ts1, ts2):\n",
    "    return(np.mean((ts1 - ts2)**2))\n",
    "\n",
    "def mae(ts1, ts2):\n",
    "    return(np.mean(np.abs(ts1 - ts2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate noise only\n",
    "\n",
    "A = slds.dynamics.As\n",
    "b = slds.dynamics.bs\n",
    "cov = slds.dynamics.Sigmas\n",
    "n_gen = 1\n",
    "n_val_frames = validation_data.shape[0]\n",
    "\n",
    "MSE = np.zeros(n_gen)\n",
    "MAE = np.zeros(n_gen)\n",
    "\n",
    "for j in range(n_gen):\n",
    "    x = [x_est[0]]\n",
    "    \n",
    "    for i in range(n_val_frames-1):\n",
    "        k = z_est[i]\n",
    "        w = np.random.multivariate_normal(np.zeros(latent_dim), cov[k])\n",
    "        x_i = w\n",
    "        x.append(x_i)\n",
    "    \n",
    "    x_gen = np.vstack(x)\n",
    "    MSE[j] = mse(x_est, x_gen)\n",
    "    MAE[j] = mae(x_est, x_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Squared Error:' ,MSE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_err_n = [mse(x_est[:t], x_gen[:t]) for t in range(1,100)]\n",
    "cum_err_n_prime = np.gradient(cum_err_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16,4))\n",
    "axs[0].plot(cum_err_n)\n",
    "axs[1].plot(cum_err_n_prime)\n",
    "axs[0].set_xlabel('Time Step')\n",
    "axs[1].set_xlabel('Time Step')\n",
    "axs[0].set_ylabel('MSE')\n",
    "axs[1].set_ylabel('d/dt MSE')\n",
    "\n",
    "plt.suptitle('Noise Only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_str = [\"$x_{%i}$\" %i for i in range(latent_dim)]\n",
    "fig, axs = plt.subplots(latent_dim,1, figsize=(14*30,2*latent_dim))\n",
    "for (d, ax) in enumerate(axs):\n",
    "    ax.plot(x_gen[:,d] + 4 * d, '-', color=colors[0], label=\"Generated\" if d==0 else None)\n",
    "    ax.plot(x_est[:,d] + 4 * d, '-', color=colors[2], label=\"Estimated\" if d==0 else None)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title_str[d], loc=\"left\", y=0.5, x=-0.03)\n",
    "axs[0].set_xticks([])\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "plt.suptitle(\"Generated and Estimated Continuous States\", va=\"bottom\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model + Noise\n",
    "\n",
    "A = slds.dynamics.As\n",
    "b = slds.dynamics.bs\n",
    "cov = slds.dynamics.Sigmas\n",
    "n_gen = 1\n",
    "n_val_frames = validation_data.shape[0]\n",
    "\n",
    "MSE = np.zeros(n_gen)\n",
    "MAE = np.zeros(n_gen)\n",
    "\n",
    "for j in range(n_gen):\n",
    "    x = [x_est[0]]\n",
    "    \n",
    "    for i in range(n_val_frames-1):\n",
    "        k = z_est[i]\n",
    "        w = np.random.multivariate_normal(np.zeros(latent_dim), cov[k])\n",
    "        x_i = A[k]@x[-1] + b[k] + w\n",
    "        x.append(x_i)\n",
    "    \n",
    "    x_gen = np.vstack(x)\n",
    "    MSE[j] = mse(x_est, x_gen)\n",
    "    MAE[j] = mae(x_est, x_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Squared Error:' ,MSE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_err_mn = [mse(x_est[:t], x_gen[:t]) for t in range(1,100)]\n",
    "cum_err_mn_prime = np.gradient(cum_err_mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16,4))\n",
    "axs[0].plot(cum_err)\n",
    "axs[1].plot(cum_err_prime)\n",
    "axs[0].set_xlabel('Time Step')\n",
    "axs[1].set_xlabel('Time Step')\n",
    "axs[0].set_ylabel('MSE')\n",
    "axs[1].set_ylabel('d/dt MSE')\n",
    "\n",
    "plt.suptitle('Model + Noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_str = [\"$x_{%i}$\" %i for i in range(latent_dim)]\n",
    "fig, axs = plt.subplots(latent_dim,1, figsize=(14*30,2*latent_dim))\n",
    "for (d, ax) in enumerate(axs):\n",
    "    ax.plot(x_gen[:,d] + 4 * d, '-', color=colors[0], label=\"Generated\" if d==0 else None)\n",
    "    ax.plot(x_est[:,d] + 4 * d, '-', color=colors[2], label=\"Estimated\" if d==0 else None)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title_str[d], loc=\"left\", y=0.5, x=-0.03)\n",
    "axs[0].set_xticks([])\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "plt.suptitle(\"Generated and Estimated Continuous States\", va=\"bottom\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model only\n",
    "\n",
    "A = slds.dynamics.As\n",
    "b = slds.dynamics.bs\n",
    "cov = slds.dynamics.Sigmas\n",
    "n_gen = 1\n",
    "n_val_frames = validation_data.shape[0]\n",
    "\n",
    "MSE = np.zeros(n_gen)\n",
    "MAE = np.zeros(n_gen)\n",
    "\n",
    "for j in range(n_gen):\n",
    "    x = [x_est[0]]\n",
    "    \n",
    "    for i in range(n_val_frames-1):\n",
    "        k = z_est[i]\n",
    "        x_i = A[k]@x[-1] + b[k]\n",
    "        x.append(x_i)\n",
    "    \n",
    "    x_gen = np.vstack(x)\n",
    "    MSE[j] = mse(x_est, x_gen)\n",
    "    MAE[j] = mae(x_est, x_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Squared Error:', MSE[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_err_m = [mse(x_est[:t], x_gen[:t]) for t in range(1,100)]\n",
    "cum_err_m_prime = np.gradient(cum_err_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(16,4))\n",
    "axs[0].plot(cum_err_m)\n",
    "axs[1].plot(cum_err_m_prime)\n",
    "axs[0].set_xlabel('Time Step')\n",
    "axs[1].set_xlabel('Time Step')\n",
    "axs[0].set_ylabel('MSE')\n",
    "axs[1].set_ylabel('d/dt MSE')\n",
    "\n",
    "plt.suptitle('Model Only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_str = [\"$x_{%i}$\" %i for i in range(latent_dim)]\n",
    "fig, axs = plt.subplots(latent_dim,1, figsize=(14*30,2*latent_dim))\n",
    "for (d, ax) in enumerate(axs):\n",
    "    ax.plot(x_gen[:,d] + 4 * d, '-', color=colors[0], label=\"Generated\" if d==0 else None)\n",
    "    ax.plot(x_est[:,d] + 4 * d, '-', color=colors[2], label=\"Estimated\" if d==0 else None)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title_str[d], loc=\"left\", y=0.5, x=-0.03)\n",
    "axs[0].set_xticks([])\n",
    "axs[0].legend(loc=\"upper right\")\n",
    "\n",
    "plt.suptitle(\"Generated and Estimated Continuous States\", va=\"bottom\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20,6))\n",
    "axs[0].plot(cum_err_n, label='Noise Only')\n",
    "axs[0].plot(cum_err_mn, label='Model + Noise')\n",
    "axs[0].plot(cum_err_m, label='Model Only')\n",
    "axs[1].plot(cum_err_n_prime, label='Noise Only')\n",
    "axs[1].plot(cum_err_mn_prime, label='Model + Noise')\n",
    "axs[1].plot(cum_err_m_prime, label='Model Only')\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "axs[0].set_xlabel('Time Step')\n",
    "axs[1].set_xlabel('Time Step')\n",
    "axs[0].set_ylabel('MSE')\n",
    "axs[1].set_ylabel('d/dt MSE')\n",
    "\n",
    "plt.suptitle('MSE Comparison')"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
